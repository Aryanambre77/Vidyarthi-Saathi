{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0Rnfd2pf-il"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the dataset\n",
        "file_path = \"/content/history_dataset  - history_qa_dataset.csv\"  # Update with your file's path\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "ghiQacp3hSCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess the data\n",
        "questions = data['Question'].tolist()\n",
        "answers = data['Answer'].tolist()"
      ],
      "metadata": {
        "id": "wNOR3xvIh90R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Train the model (TF-IDF Vectorizer)\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(questions)\n",
        "\n",
        "# Helper function to suggest similar questions\n",
        "def suggest_similar_questions(query, top_n=3):\n",
        "    query_vector = vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
        "    similar_indices = similarities.argsort()[0, -top_n:][::-1]\n",
        "\n",
        "    suggestions = []\n",
        "    for idx in similar_indices:\n",
        "        if similarities[0][idx] > 0:  # Only consider positive similarity scores\n",
        "            suggestions.append(questions[idx])\n",
        "    return suggestions"
      ],
      "metadata": {
        "id": "eiRE5pcqiHnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the History Chatbot!\")\n",
        "    print(\"You can ask questions from the textbook, and I'll try my best to answer them.\")\n",
        "    print(\"If you're unsure how to phrase your question, I can suggest similar ones.\")\n",
        "    print(\"Type 'exit' to end the session.\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"\\nType your question: \").strip()\n",
        "        if user_query.lower() == \"exit\":\n",
        "            print(\"Thank you for using the History Chatbot. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Process the user's query\n",
        "        query_vector = vectorizer.transform([user_query])\n",
        "        similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
        "\n",
        "        # Get the highest similarity score\n",
        "        max_similarity_index = np.argmax(similarities)\n",
        "        max_similarity_score = similarities[0][max_similarity_index]\n",
        "\n",
        "        # Threshold to determine if the question is out of scope\n",
        "        threshold = 0.3  # You can adjust this value\n",
        "\n",
        "        if max_similarity_score > threshold:\n",
        "            response = answers[max_similarity_index]\n",
        "            print(f\"Answer: {response}\")\n",
        "        else:\n",
        "            print(\"I'm not sure about that. It seems your question isn't directly from the textbook.\")\n",
        "            print(\"Here are some similar questions you could try:\")\n",
        "            suggestions = suggest_similar_questions(user_query)\n",
        "            for i, suggestion in enumerate(suggestions, start=1):\n",
        "                print(f\"{i}. {suggestion}\")\n",
        "            print(\"Please refine your question based on these suggestions or ask something else.\")"
      ],
      "metadata": {
        "id": "N0RXiWdiiNDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVxVM8PYiUD9",
        "outputId": "fb2590cb-3a5c-48db-ab12-8e2e12926f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the History Chatbot!\n",
            "You can ask questions from the textbook, and I'll try my best to answer them.\n",
            "If you're unsure how to phrase your question, I can suggest similar ones.\n",
            "Type 'exit' to end the session.\n",
            "\n",
            "Type your question: material\n",
            "Answer: Material sources include objects, monuments, places, coins, and sculptures. Examples are buildings, bridges, and forts from the British period, such as the Cellular Jail in Andaman.\n",
            "\n",
            "Type your question: exit\n",
            "Thank you for using the History Chatbot. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the test dataset\n",
        "test_file_path = \"/content/history_dataset  - history_qa_dataset.csv\"  # Update with your test file path\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "# Ensure data is in expected format\n",
        "assert \"Question\" in test_data.columns and \"Answer\" in test_data.columns, \"CSV must have 'Question' and 'Answer' columns.\"\n",
        "\n",
        "# Step 2: Extract test questions and answers\n",
        "test_questions = test_data['Question'].tolist()\n",
        "test_answers = test_data['Answer'].tolist()\n",
        "\n",
        "# Step 3: Evaluate the chatbot model\n",
        "correct_predictions = 0\n",
        "threshold = 0.3  # Similarity score threshold to consider a match\n",
        "\n",
        "for i, test_question in enumerate(test_questions):\n",
        "    # Transform the test question into the TF-IDF vector space\n",
        "    test_vector = vectorizer.transform([test_question])\n",
        "    similarities = cosine_similarity(test_vector, tfidf_matrix)\n",
        "\n",
        "    # Get the most similar question from the training data\n",
        "    max_similarity_index = np.argmax(similarities)\n",
        "    max_similarity_score = similarities[0][max_similarity_index]\n",
        "\n",
        "    # If the similarity score exceeds the threshold, retrieve the answer\n",
        "    if max_similarity_score > threshold:\n",
        "        predicted_answer = answers[max_similarity_index]\n",
        "    else:\n",
        "        predicted_answer = None  # Indicate no confident match found\n",
        "\n",
        "    # Compare the predicted answer with the actual test answer\n",
        "    if predicted_answer == test_answers[i]:\n",
        "        correct_predictions += 1\n",
        "\n",
        "# Step 4: Calculate accuracy\n",
        "total_questions = len(test_questions)\n",
        "accuracy = (correct_predictions / total_questions) * 100\n",
        "\n",
        "print(f\"Accuracy of the chatbot model: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONR2ZF6EyRdX",
        "outputId": "a591b7ea-690b-4cf0-923d-aba1cb9d15b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the chatbot model: 92.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "file_path = \"history_dataset.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "assert \"Question\" in data.columns and \"Answer\" in data.columns, \"CSV must have 'Question' and 'Answer' columns.\"\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = [word for word in text.split() if word.lower() not in stop_words]\n",
        "    stemmed = [stemmer.stem(word) for word in tokens]\n",
        "    lemmatized = [lemmatizer.lemmatize(word) for word in stemmed]\n",
        "    return ' '.join(lemmatized)\n",
        "\n",
        "data['ProcessedQuestion'] = data['Question'].apply(preprocess)\n",
        "questions = data['ProcessedQuestion'].tolist()\n",
        "answers = data['Answer'].tolist()\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(questions)\n",
        "\n",
        "def chatbot():\n",
        "    print(\"Welcome to the History Chatbot!\")\n",
        "    print(\"You can ask questions using keywords like '1784', 'Powada', or names like 'Sir William Jones'.\")\n",
        "    print(\"Type 'exit' to end the session.\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"\\nType your question: \").strip()\n",
        "        if user_query.lower() == \"exit\":\n",
        "            print(\"Thank you for using the History Chatbot. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        query = preprocess(user_query)\n",
        "        query_vector = vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
        "\n",
        "        max_similarity_index = np.argmax(similarities)\n",
        "        max_similarity_score = similarities[0][max_similarity_index]\n",
        "\n",
        "        threshold = 0.3\n",
        "\n",
        "        if max_similarity_score > threshold:\n",
        "            response = answers[max_similarity_index]\n",
        "            print(f\"Answer: {response}\")\n",
        "        else:\n",
        "            print(\"I'm not sure about that. Try using keywords or rephrasing your question.\")\n",
        "\n",
        "if _name_ == \"_main_\":\n",
        "    chatbot()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvxV-mIet85v",
        "outputId": "0e346fe2-dac2-44a9-a26a-907ae35d0868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}